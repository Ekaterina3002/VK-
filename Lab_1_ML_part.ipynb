{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогноз дружбы с помощью CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3e82de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68e155",
   "metadata": {},
   "source": [
    "## 1. Загрузка и первичный анализ данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e2e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data(features_file, users_file=None, friends_file=None, drop_unrealistic_age=True):\n",
    "    print(\"Запускаю чтение исходных таблиц, не пугайтесь стенки текста.\")\n",
    "\n",
    "    features_path = Path(features_file)\n",
    "    if not features_path.exists():\n",
    "        raise FileNotFoundError(f\"Не найден файл с признаками: {features_file}\")\n",
    "\n",
    "    df = pd.read_csv(features_path)\n",
    "    print(f\"Сырые размеры: {df.shape}\")\n",
    "    print(f\"Колонки, что нашлись: {df.columns.tolist()}\")\n",
    "\n",
    "    df = df.dropna(subset=['user_A', 'user_B']).copy()\n",
    "    df[['user_A', 'user_B']] = df[['user_A', 'user_B']].astype('int64')\n",
    "    df = df.drop_duplicates(subset=['user_A', 'user_B']).reset_index(drop=True)\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    count_cols = ['common_friends', 'common_groups']\n",
    "    for col in count_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0).astype('int32')\n",
    "\n",
    "    binary_cols = [col for col in df.columns if col.startswith('same_')]\n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].fillna(0).astype('int8')\n",
    "\n",
    "    ratio_cols = ['jaccard_friends', 'adamic_adar', 'jaccard_groups']\n",
    "    for col in ratio_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if friends_file is not None:\n",
    "        friends_path = Path(friends_file)\n",
    "        friends_df = pd.read_csv(friends_path)\n",
    "        friends_df = friends_df.dropna(subset=['user_A', 'user_B']).copy()\n",
    "        friends_df[['user_A', 'user_B']] = friends_df[['user_A', 'user_B']].astype('int64')\n",
    "\n",
    "        undirected = pd.concat([\n",
    "            friends_df[['user_A', 'user_B']],\n",
    "            friends_df[['user_B', 'user_A']].rename(columns={'user_B': 'user_A', 'user_A': 'user_B'}),\n",
    "        ], ignore_index=True).drop_duplicates()\n",
    "        undirected['label'] = 1\n",
    "\n",
    "        df = df.drop(columns=['label'], errors='ignore')\n",
    "        df = df.merge(undirected, on=['user_A', 'user_B'], how='left')\n",
    "        df['label'] = df['label'].fillna(0).astype('int8')\n",
    "        print(f\"Таргет собран: {int(df['label'].sum())} дружб из {len(df)} пар (доля {df['label'].mean():.4%})\")\n",
    "    elif 'label' not in df.columns:\n",
    "        raise ValueError(\"В таблице признаков нет колонки label и не передан friends_file для построения таргета\")\n",
    "\n",
    "    if users_file is not None and drop_unrealistic_age:\n",
    "        users_path = Path(users_file)\n",
    "        users_df = pd.read_csv(users_path)\n",
    "        invalid_ids = users_df[(users_df['age'].notna()) & ((users_df['age'] < 14) | (users_df['age'] > 90))]['id']\n",
    "        invalid_ids = invalid_ids.astype('int64') if not invalid_ids.empty else pd.Series([], dtype='int64')\n",
    "        if not invalid_ids.empty:\n",
    "            before = len(df)\n",
    "            df = df[~df['user_A'].isin(invalid_ids) & ~df['user_B'].isin(invalid_ids)].copy()\n",
    "            removed = before - len(df)\n",
    "            print(f\"Срезал странные возрасты, минус {removed} строк\")\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"После чистки осталось: {df.shape}\")\n",
    "\n",
    "    print(\"\\nИнформация о фрейме для спокойствия:\")\n",
    "    df.info()\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(\"\\nЧисловая статистика без прикрас:\")\n",
    "    print(df[numeric_cols].describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]))\n",
    "\n",
    "    print(\"\\nГде дырки в данных:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({'Количество': missing_data, 'Процент': missing_percent})\n",
    "    print(missing_df[missing_df['Количество'] > 0].sort_values('Процент', ascending=False))\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        print(\"\\nКак распределён таргет:\")\n",
    "        label_counts = df['label'].value_counts()\n",
    "        print(label_counts)\n",
    "        print(label_counts / len(df))\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        label_counts.plot(kind='bar', color=['salmon', 'steelblue'])\n",
    "        plt.title('Распределение целевой переменной')\n",
    "        plt.xlabel('label')\n",
    "        plt.ylabel('Количество пар')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        label_counts.plot(kind='pie', autopct='%1.2f%%', colors=['salmon', 'steelblue'])\n",
    "        plt.ylabel('')\n",
    "        plt.title('Соотношение классов')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3b61c",
   "metadata": {},
   "source": [
    "## 2. Помощники для генерации отрицательных примеров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17ad00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_text(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    text = str(value).strip()\n",
    "    return text.lower() if text else None\n",
    "\n",
    "\n",
    "def _parse_multi_value_field(value):\n",
    "    if pd.isna(value):\n",
    "        return set()\n",
    "    tokens = str(value).split(';')\n",
    "    return {token.strip().lower() for token in tokens if token.strip()}\n",
    "\n",
    "\n",
    "def _prepare_user_profiles(users_df):\n",
    "    profiles = {}\n",
    "    for row in users_df.itertuples(index=False):\n",
    "        user_id = int(getattr(row, 'id'))\n",
    "        age_value = getattr(row, 'age', np.nan)\n",
    "        if pd.isna(age_value):\n",
    "            age = None\n",
    "        else:\n",
    "            try:\n",
    "                age = float(age_value)\n",
    "            except (TypeError, ValueError):\n",
    "                age = None\n",
    "\n",
    "        profiles[user_id] = {\n",
    "            'city': _normalize_text(getattr(row, 'city', None)),\n",
    "            'universities': _parse_multi_value_field(getattr(row, 'universities', None)),\n",
    "            'faculties': _parse_multi_value_field(getattr(row, 'faculties', None)),\n",
    "            'schools': _parse_multi_value_field(getattr(row, 'schools', None)),\n",
    "            'age': age,\n",
    "        }\n",
    "    return profiles\n",
    "\n",
    "\n",
    "def _build_friend_graph(friends_df, valid_user_ids=None):\n",
    "    graph = defaultdict(set)\n",
    "    for row in friends_df.itertuples(index=False):\n",
    "        user_a = int(getattr(row, 'user_A'))\n",
    "        user_b = int(getattr(row, 'user_B'))\n",
    "        if valid_user_ids is not None and (user_a not in valid_user_ids or user_b not in valid_user_ids):\n",
    "            continue\n",
    "        graph[user_a].add(user_b)\n",
    "        graph[user_b].add(user_a)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def _build_group_membership(groups_df, valid_user_ids=None):\n",
    "    membership = defaultdict(set)\n",
    "    for row in groups_df.itertuples(index=False):\n",
    "        user_id = int(getattr(row, 'user_id'))\n",
    "        if valid_user_ids is not None and user_id not in valid_user_ids:\n",
    "            continue\n",
    "        group_id = int(getattr(row, 'group_id'))\n",
    "        membership[user_id].add(group_id)\n",
    "    return membership\n",
    "\n",
    "\n",
    "def compute_pair_features(user_a, user_b, friend_graph, user_profiles, group_membership):\n",
    "    friends_a = friend_graph.get(user_a, set())\n",
    "    friends_b = friend_graph.get(user_b, set())\n",
    "    common_friends = friends_a & friends_b\n",
    "    union_friends = friends_a | friends_b\n",
    "\n",
    "    jaccard_friends = len(common_friends) / len(union_friends) if union_friends else 0.0\n",
    "\n",
    "    adamic_adar = 0.0\n",
    "    for friend in common_friends:\n",
    "        degree = len(friend_graph.get(friend, set()))\n",
    "        if degree > 1:\n",
    "            adamic_adar += 1.0 / np.log(degree)\n",
    "\n",
    "    profile_a = user_profiles.get(user_a, {})\n",
    "    profile_b = user_profiles.get(user_b, {})\n",
    "\n",
    "    same_city = int(bool(profile_a.get('city') and profile_a.get('city') == profile_b.get('city')))\n",
    "    same_university = int(bool(profile_a.get('universities', set()) & profile_b.get('universities', set())))\n",
    "    same_faculty = int(bool(profile_a.get('faculties', set()) & profile_b.get('faculties', set())))\n",
    "    same_school = int(bool(profile_a.get('schools', set()) & profile_b.get('schools', set())))\n",
    "\n",
    "    age_a = profile_a.get('age')\n",
    "    age_b = profile_b.get('age')\n",
    "    age_diff = float(abs(age_a - age_b)) if age_a is not None and age_b is not None else np.nan\n",
    "\n",
    "    groups_a = group_membership.get(user_a, set())\n",
    "    groups_b = group_membership.get(user_b, set())\n",
    "    common_groups = groups_a & groups_b\n",
    "    union_groups = groups_a | groups_b\n",
    "    jaccard_groups = len(common_groups) / len(union_groups) if union_groups else 0.0\n",
    "\n",
    "    return {\n",
    "        'common_friends': int(len(common_friends)),\n",
    "        'jaccard_friends': float(jaccard_friends),\n",
    "        'adamic_adar': float(adamic_adar),\n",
    "        'same_city': int(same_city),\n",
    "        'same_university': int(same_university),\n",
    "        'same_faculty': int(same_faculty),\n",
    "        'same_school': int(same_school),\n",
    "        'age_diff': age_diff,\n",
    "        'common_groups': int(len(common_groups)),\n",
    "        'jaccard_groups': float(jaccard_groups),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d992f",
   "metadata": {},
   "source": [
    "## 3. Добавление отрицательных примеров и ресемплинг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88847b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_additional_negative_samples(existing_df, users_df, friends_df, groups_df, num_samples, random_state=42, max_attempts_multiplier=20):\n",
    "    if num_samples <= 0:\n",
    "        return pd.DataFrame(columns=existing_df.columns)\n",
    "\n",
    "    users_df = users_df.dropna(subset=['id']).copy()\n",
    "    users_df['id'] = users_df['id'].astype('int64')\n",
    "\n",
    "    friends_df = friends_df.dropna(subset=['user_A', 'user_B']).copy()\n",
    "    friends_df[['user_A', 'user_B']] = friends_df[['user_A', 'user_B']].astype('int64')\n",
    "\n",
    "    groups_df = groups_df.dropna(subset=['user_id', 'group_id']).copy()\n",
    "    groups_df[['user_id', 'group_id']] = groups_df[['user_id', 'group_id']].astype('int64')\n",
    "\n",
    "    valid_user_ids = set(users_df['id'].tolist())\n",
    "    friend_graph = _build_friend_graph(friends_df, valid_user_ids=valid_user_ids)\n",
    "    group_membership = _build_group_membership(groups_df, valid_user_ids=valid_user_ids)\n",
    "    user_profiles = _prepare_user_profiles(users_df)\n",
    "\n",
    "    existing_pairs = {\n",
    "        (min(int(row.user_A), int(row.user_B)), max(int(row.user_A), int(row.user_B)))\n",
    "        for row in existing_df[['user_A', 'user_B']].itertuples(index=False)\n",
    "    }\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    user_pool = np.array(list(valid_user_ids))\n",
    "\n",
    "    samples = []\n",
    "    attempts = 0\n",
    "    max_attempts = max(num_samples * max_attempts_multiplier, num_samples * 2)\n",
    "\n",
    "    while len(samples) < num_samples and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        if len(user_pool) < 2:\n",
    "            break\n",
    "\n",
    "        user_a, user_b = rng.choice(user_pool, size=2, replace=False)\n",
    "        user_a, user_b = int(min(user_a, user_b)), int(max(user_a, user_b))\n",
    "        if user_a == user_b:\n",
    "            continue\n",
    "\n",
    "        pair_key = (user_a, user_b)\n",
    "        if pair_key in existing_pairs:\n",
    "            continue\n",
    "\n",
    "        if user_b in friend_graph.get(user_a, set()):\n",
    "            continue\n",
    "\n",
    "        feature_values = compute_pair_features(user_a, user_b, friend_graph, user_profiles, group_membership)\n",
    "        feature_values.update({'user_A': user_a, 'user_B': user_b, 'label': 0})\n",
    "        samples.append(feature_values)\n",
    "        existing_pairs.add(pair_key)\n",
    "\n",
    "    if len(samples) < num_samples:\n",
    "        print(f\"Сгенерил только {len(samples)} из {num_samples} отрицательных пар, дальше не вытянул.\")\n",
    "\n",
    "    if not samples:\n",
    "        return pd.DataFrame(columns=existing_df.columns)\n",
    "\n",
    "    new_samples_df = pd.DataFrame(samples)\n",
    "    for col in existing_df.columns:\n",
    "        if col not in new_samples_df.columns:\n",
    "            new_samples_df[col] = np.nan\n",
    "    new_samples_df = new_samples_df[existing_df.columns]\n",
    "\n",
    "    for col in existing_df.select_dtypes(include=['int8', 'int16', 'int32', 'int64']).columns:\n",
    "        new_samples_df[col] = new_samples_df[col].round().astype(existing_df[col].dtype, errors='ignore')\n",
    "\n",
    "    return new_samples_df\n",
    "\n",
    "\n",
    "def augment_dataset_with_negatives(df, users_file, friends_file, groups_file, negative_config=None, drop_unrealistic_age=True):\n",
    "    if not negative_config:\n",
    "        return df, 0\n",
    "\n",
    "    if users_file is None or friends_file is None or groups_file is None:\n",
    "        raise ValueError(\"Для генерации отрицательных примеров нужны файлы users, friends и groups.\")\n",
    "\n",
    "    num_samples = negative_config.get('num_samples', 0)\n",
    "    multiplier = negative_config.get('multiplier')\n",
    "    if multiplier is not None:\n",
    "        positives = int((df['label'] == 1).sum())\n",
    "        num_samples = max(num_samples, int(positives * multiplier))\n",
    "\n",
    "    if num_samples <= 0:\n",
    "        print(\"Конфиг с отрицательными примерами пустой, пропускаю шаг.\")\n",
    "        return df, 0\n",
    "\n",
    "    random_state = negative_config.get('random_state', 42)\n",
    "    max_attempts_multiplier = negative_config.get('max_attempts_multiplier', 20)\n",
    "\n",
    "    users_df = pd.read_csv(users_file)\n",
    "    if drop_unrealistic_age:\n",
    "        invalid_ids = users_df[(users_df['age'].notna()) & ((users_df['age'] < 14) | (users_df['age'] > 90))]['id']\n",
    "        if not invalid_ids.empty:\n",
    "            users_df = users_df[~users_df['id'].isin(invalid_ids)].copy()\n",
    "\n",
    "    friends_df = pd.read_csv(friends_file)\n",
    "    groups_df = pd.read_csv(groups_file)\n",
    "\n",
    "    added_df = generate_additional_negative_samples(\n",
    "        existing_df=df,\n",
    "        users_df=users_df,\n",
    "        friends_df=friends_df,\n",
    "        groups_df=groups_df,\n",
    "        num_samples=num_samples,\n",
    "        random_state=random_state,\n",
    "        max_attempts_multiplier=max_attempts_multiplier,\n",
    "    )\n",
    "\n",
    "    if added_df.empty:\n",
    "        return df, 0\n",
    "\n",
    "    combined_df = pd.concat([df, added_df], ignore_index=True)\n",
    "    print(f\"Докинул {len(added_df)} отрицательных пар, теперь данных {combined_df.shape}\")\n",
    "    return combined_df, len(added_df)\n",
    "\n",
    "\n",
    "def resample_dataset(df, target_col='label', strategy=None, ratio=1.0, random_state=42):\n",
    "    if strategy is None:\n",
    "        return df\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Не найдена целевая колонка '{target_col}' для ресемплинга.\")\n",
    "\n",
    "    if ratio <= 0:\n",
    "        raise ValueError(\"Параметр ratio должен быть больше 0.\")\n",
    "\n",
    "    positives = df[df[target_col] == 1]\n",
    "    negatives = df[df[target_col] == 0]\n",
    "\n",
    "    if positives.empty or negatives.empty:\n",
    "        print(\"Классов не хватает, балансировать нечего.\")\n",
    "        return df\n",
    "\n",
    "    if strategy == 'undersample':\n",
    "        target_negatives = min(len(negatives), int(len(positives) * ratio))\n",
    "        if target_negatives == 0:\n",
    "            print(\"Не хватило строк для undersample, оставляю как есть.\")\n",
    "            return df\n",
    "        negatives_resampled = resample(\n",
    "            negatives, replace=False, n_samples=target_negatives, random_state=random_state\n",
    "        )\n",
    "        resampled_df = pd.concat([positives, negatives_resampled], ignore_index=True)\n",
    "    elif strategy == 'oversample':\n",
    "        target_positives = max(len(positives), int(np.ceil(len(negatives) / ratio)))\n",
    "        positives_resampled = resample(\n",
    "            positives, replace=True, n_samples=target_positives, random_state=random_state\n",
    "        )\n",
    "        resampled_df = pd.concat([positives_resampled, negatives], ignore_index=True)\n",
    "    elif strategy == 'balanced':\n",
    "        target_size = min(len(positives), len(negatives))\n",
    "        positives_resampled = resample(\n",
    "            positives, replace=len(positives) < target_size, n_samples=target_size, random_state=random_state\n",
    "        )\n",
    "        negatives_resampled = resample(\n",
    "            negatives, replace=len(negatives) < target_size, n_samples=target_size, random_state=random_state\n",
    "        )\n",
    "        resampled_df = pd.concat([positives_resampled, negatives_resampled], ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестная стратегия ресемплинга: {strategy}\")\n",
    "\n",
    "    resampled_df = resampled_df.sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "    print(f\"Ресемплинг {strategy}: {resampled_df[target_col].value_counts().to_dict()}\")\n",
    "    return resampled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6592b7",
   "metadata": {},
   "source": [
    "## 4. Аналитика признаков и подготовка выборок\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a36d0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(df, target_col='label'):\n",
    "    print(\"Смотрю на признаки, вдруг что-то выбивается.\")\n",
    "\n",
    "    feature_cols = [col for col in df.columns if col not in ['user_A', 'user_B', target_col]]\n",
    "\n",
    "    target_correlations = pd.Series(dtype=float)\n",
    "\n",
    "    if target_col in df.columns:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        correlation_matrix = df[feature_cols + [target_col]].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                    fmt='.2f', linewidths=0.5)\n",
    "        plt.title('Матрица корреляций признаков')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nКорреляции с таргетом:\")\n",
    "        target_correlations = correlation_matrix[target_col].drop(target_col).sort_values(ascending=False)\n",
    "        for feature, corr in target_correlations.items():\n",
    "            print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "    numeric_features = df[feature_cols].select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    if not target_correlations.empty and len(numeric_features) > 8:\n",
    "        top_features = target_correlations.abs().nlargest(8).index\n",
    "    else:\n",
    "        top_features = numeric_features[:8] if len(numeric_features) > 8 else numeric_features\n",
    "\n",
    "    if len(top_features) > 0:\n",
    "        rows = int(np.ceil(len(top_features) / 4))\n",
    "        cols = min(4, len(top_features))\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "\n",
    "        for i, feature in enumerate(top_features):\n",
    "            if target_col in df.columns:\n",
    "                sns.boxplot(x=df[target_col], y=df[feature], ax=axes[i])\n",
    "                axes[i].set_title(f'{feature} по классам')\n",
    "            else:\n",
    "                df[feature].hist(bins=30, ax=axes[i])\n",
    "                axes[i].set_title(f'Распределение {feature}')\n",
    "            axes[i].grid(True, alpha=0.2)\n",
    "\n",
    "        for j in range(len(top_features), len(axes)):\n",
    "            axes[j].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return feature_cols\n",
    "\n",
    "def prepare_data(df, target_col='label', test_size=0.2, val_size=0.2, random_state=42):\n",
    "    print(\"Готовлю выборки для обучения.\")\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Не найдена целевая колонка '{target_col}' в датасете\")\n",
    "\n",
    "    df_clean = df.drop(['user_A', 'user_B'], axis=1, errors='ignore').copy()\n",
    "\n",
    "    X = df_clean.drop(target_col, axis=1)\n",
    "    y = df_clean[target_col]\n",
    "\n",
    "    feature_names = X.columns.tolist()\n",
    "    print(f\"В игру идут {len(feature_names)} признаков: {feature_names}\")\n",
    "\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_relative_size, random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(\"Размеры выборок получились такие:\")\n",
    "    print(f\"train -> {X_train.shape}\")\n",
    "    print(f\"val -> {X_val.shape}\")\n",
    "    print(f\"test -> {X_test.shape}\")\n",
    "\n",
    "    class_counts = y_train.value_counts()\n",
    "    pos_weight = class_counts.get(0, 1) / class_counts.get(1, 1)\n",
    "    class_weights = {0: 1.0, 1: pos_weight}\n",
    "    print(f\"Классы в train: {class_counts.to_dict()}, веса {class_weights}\")\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, feature_names, class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80279ca1",
   "metadata": {},
   "source": [
    "## 5. Модель CatBoost и оценка качества\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d61bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost_model(X_train, X_val, y_train, y_val, feature_names, class_weights=None):\n",
    "    print(\"Запускаю CatBoost, наберитесь терпения.\")\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, feature_names=feature_names)\n",
    "    val_pool = Pool(X_val, y_val, feature_names=feature_names)\n",
    "\n",
    "    params = dict(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=100,\n",
    "        thread_count=-1,\n",
    "        use_best_model=True,\n",
    "        l2_leaf_reg=3.0,\n",
    "    )\n",
    "\n",
    "    if class_weights is not None:\n",
    "        ordered_classes = sorted(class_weights.keys())\n",
    "        params['class_weights'] = [class_weights[c] for c in ordered_classes]\n",
    "        print(f\"Весам классов дал: {params['class_weights']}\")\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    print(\"Считаю метрики по train/val/test.\")\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"\\nROC-AUC по выборкам:\")\n",
    "    print(f\"train: {train_auc:.4f}\")\n",
    "    print(f\"val: {val_auc:.4f}\")\n",
    "    print(f\"test: {test_auc:.4f}\")\n",
    "\n",
    "    y_train_class = model.predict(X_train)\n",
    "    y_val_class = model.predict(X_val)\n",
    "    y_test_class = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_class)\n",
    "    val_acc = accuracy_score(y_val, y_val_class)\n",
    "    test_acc = accuracy_score(y_test, y_test_class)\n",
    "    print(\"\\nAccuracy по выборкам:\")\n",
    "    print(f\"train: {train_acc:.4f}\")\n",
    "    print(f\"val: {val_acc:.4f}\")\n",
    "    print(f\"test: {test_acc:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i, (y_true, y_pred, name) in enumerate([\n",
    "        (y_train, y_train_pred, 'Train'),\n",
    "        (y_val, y_val_pred, 'Validation'),\n",
    "        (y_test, y_test_pred, 'Test')\n",
    "    ]):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    datasets = [\n",
    "        ('Train', y_train, y_train_class),\n",
    "        ('Validation', y_val, y_val_class),\n",
    "        ('Test', y_test, y_test_class),\n",
    "    ]\n",
    "\n",
    "    for idx, (name, y_true, y_pred_class) in enumerate(datasets, start=1):\n",
    "        plt.subplot(1, 3, idx)\n",
    "        cm = confusion_matrix(y_true, y_pred_class)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'train_auc': train_auc,\n",
    "        'val_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'test_acc': test_acc,\n",
    "    }\n",
    "\n",
    "def analyze_feature_importance(model, feature_names):\n",
    "    print(\"Смотрю, какие признаки тянут модель.\")\n",
    "\n",
    "    feature_importance = model.get_feature_importance()\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\nТоп-15 по важности:\")\n",
    "    print(importance_df.head(15))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    top_features = importance_df.head(15)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(top_features['feature'], top_features['importance'])\n",
    "    plt.xlabel('Важность')\n",
    "    plt.title('Топ-15 самых важных признаков')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(feature_importance, bins=30, alpha=0.7, color='skyblue')\n",
    "    plt.xlabel('Важность признака')\n",
    "    plt.ylabel('Количество')\n",
    "    plt.title('Распределение важности признаков')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737d1b3",
   "metadata": {},
   "source": [
    "## 6. Основной пайплайн и эксперименты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ee18d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    negative_sampling_config=None,\n",
    "    resampling_config=None,\n",
    "    drop_unrealistic_age=True,\n",
    "    random_state=42,\n",
    "):\n",
    "    print(\"Гоняю весь пайплайн от начала до конца.\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    base_dir = Path('data')\n",
    "    features_path = base_dir / 'Features.csv'\n",
    "    users_path = base_dir / 'Users.csv'\n",
    "    friends_path = base_dir / 'Friends.csv'\n",
    "    groups_path = base_dir / 'Groups.csv'\n",
    "\n",
    "    df = load_and_explore_data(\n",
    "        features_path,\n",
    "        users_file=users_path,\n",
    "        friends_file=friends_path,\n",
    "        drop_unrealistic_age=drop_unrealistic_age,\n",
    "    )\n",
    "\n",
    "    if negative_sampling_config:\n",
    "        df, added_negatives = augment_dataset_with_negatives(\n",
    "            df,\n",
    "            users_file=users_path,\n",
    "            friends_file=friends_path,\n",
    "            groups_file=groups_path,\n",
    "            negative_config=negative_sampling_config,\n",
    "            drop_unrealistic_age=drop_unrealistic_age,\n",
    "        )\n",
    "        if added_negatives:\n",
    "            class_breakdown = df['label'].value_counts().to_dict()\n",
    "            print(f\"После подмешивания отрицательных пар баланс такой: {class_breakdown}\")\n",
    "\n",
    "    if resampling_config and resampling_config.get('strategy'):\n",
    "        df = resample_dataset(\n",
    "            df,\n",
    "            target_col=resampling_config.get('target_col', 'label'),\n",
    "            strategy=resampling_config.get('strategy'),\n",
    "            ratio=resampling_config.get('ratio', 1.0),\n",
    "            random_state=resampling_config.get('random_state', random_state),\n",
    "        )\n",
    "\n",
    "    feature_cols = analyze_features(df)\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, feature_names, class_weights = prepare_data(\n",
    "        df, random_state=random_state\n",
    "    )\n",
    "\n",
    "    model = train_catboost_model(X_train, X_val, y_train, y_val, feature_names, class_weights)\n",
    "\n",
    "    metrics = evaluate_model(model, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "    importance_df = analyze_feature_importance(model, feature_names)\n",
    "\n",
    "    print(\"\\nГотово, вот финальные цифры:\")\n",
    "    print(f\"ROC-AUC на тесте: {metrics['test_auc']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['test_acc']:.4f}\")\n",
    "\n",
    "    model.save_model('catboost_friendship_model.cbm')\n",
    "    print(\"Сохранил модель в catboost_friendship_model.cbm\")\n",
    "\n",
    "    return model, importance_df, metrics\n",
    "\n",
    "def feature_ablation_study(df, target_col='label'):\n",
    "    print(\"\\nСмотрю, сколько пользы от разных групп признаков.\")\n",
    "\n",
    "    feature_groups = {\n",
    "        'Графовые': ['common_friends', 'jaccard_friends', 'adamic_adar'],\n",
    "        'Гео': ['same_city'],\n",
    "        'Образование': ['same_university', 'same_faculty', 'same_school'],\n",
    "        'Группы': ['common_groups', 'jaccard_groups'],\n",
    "        'Демография': ['age_diff'],\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for group_name, features in feature_groups.items():\n",
    "        available_features = [f for f in features if f in df.columns]\n",
    "        if len(available_features) == 0:\n",
    "            continue\n",
    "\n",
    "        X = df[available_features]\n",
    "        y = df[target_col]\n",
    "\n",
    "        pos_weight = max(1.0, (y == 0).sum() / max((y == 1).sum(), 1))\n",
    "        model = CatBoostClassifier(iterations=300, verbose=False, random_seed=42, class_weights=[1.0, pos_weight])\n",
    "        cv_scores = cross_val_score(model, X, y, cv=3, scoring='roc_auc')\n",
    "\n",
    "        results[group_name] = {\n",
    "            'mean_auc': cv_scores.mean(),\n",
    "            'features': available_features\n",
    "        }\n",
    "\n",
    "        print(f\"{group_name}: AUC = {cv_scores.mean():.4f} ({', '.join(available_features)})\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949d489",
   "metadata": {},
   "source": [
    "## 7. Запуск пайплайна (пример конфигурации)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "204da454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гоняю весь пайплайн от начала до конца.\n",
      "----------------------------------------\n",
      "Запускаю чтение исходных таблиц, не пугайтесь стенки текста.\n",
      "Сырые размеры: (371909, 12)\n",
      "Колонки, что нашлись: ['user_A', 'user_B', 'common_friends', 'jaccard_friends', 'adamic_adar', 'same_city', 'same_university', 'same_faculty', 'same_school', 'age_diff', 'common_groups', 'jaccard_groups']\n",
      "Таргет собран: 1304 дружб из 370803 пар (доля 0.3517%)\n",
      "После чистки осталось: (370803, 13)\n",
      "\n",
      "Информация о фрейме для спокойствия:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370803 entries, 0 to 370802\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   user_A           370803 non-null  int64  \n",
      " 1   user_B           370803 non-null  int64  \n",
      " 2   common_friends   370803 non-null  int32  \n",
      " 3   jaccard_friends  370803 non-null  float64\n",
      " 4   adamic_adar      370803 non-null  float64\n",
      " 5   same_city        370803 non-null  int8   \n",
      " 6   same_university  370803 non-null  int8   \n",
      " 7   same_faculty     370803 non-null  int8   \n",
      " 8   same_school      370803 non-null  int8   \n",
      " 9   age_diff         56627 non-null   float64\n",
      " 10  common_groups    370803 non-null  int32  \n",
      " 11  jaccard_groups   370802 non-null  float64\n",
      " 12  label            370803 non-null  int8   \n",
      "dtypes: float64(4), int32(2), int64(2), int8(5)\n",
      "memory usage: 21.6 MB\n",
      "\n",
      "Числовая статистика без прикрас:\n",
      "             user_A        user_B  common_friends  jaccard_friends  \\\n",
      "count  3.708030e+05  3.708030e+05   370803.000000    370803.000000   \n",
      "mean   5.187693e+07  3.345570e+08        0.337546         0.000371   \n",
      "std    3.992414e+07  1.730810e+08        4.595803         0.003541   \n",
      "min    2.257010e+05  3.057350e+05        0.000000         0.000000   \n",
      "1%     3.057350e+05  2.802734e+07        0.000000         0.000000   \n",
      "5%     1.870120e+06  1.041939e+08        0.000000         0.000000   \n",
      "50%    4.781879e+07  2.978683e+08        0.000000         0.000000   \n",
      "95%    1.238258e+08  6.699075e+08        1.000000         0.001388   \n",
      "99%    1.372270e+08  8.084938e+08        4.000000         0.006465   \n",
      "max    1.380165e+08  1.071774e+09      623.000000         0.294118   \n",
      "\n",
      "         adamic_adar      same_city  same_university   same_faculty  \\\n",
      "count  370803.000000  370803.000000    370803.000000  370803.000000   \n",
      "mean        0.021740       0.134287         0.000936       0.000111   \n",
      "std         0.116725       0.340961         0.030577       0.010515   \n",
      "min         0.000000       0.000000         0.000000       0.000000   \n",
      "1%          0.000000       0.000000         0.000000       0.000000   \n",
      "5%          0.000000       0.000000         0.000000       0.000000   \n",
      "50%         0.000000       0.000000         0.000000       0.000000   \n",
      "95%         0.164107       1.000000         0.000000       0.000000   \n",
      "99%         0.329308       1.000000         0.000000       0.000000   \n",
      "max         9.318961       1.000000         1.000000       1.000000   \n",
      "\n",
      "         same_school      age_diff  common_groups  jaccard_groups  \\\n",
      "count  370803.000000  56627.000000  370803.000000   370802.000000   \n",
      "mean        0.000785     13.080827       1.097936        0.002340   \n",
      "std         0.028003      9.694750       3.196154        0.005411   \n",
      "min         0.000000      0.000000       0.000000        0.000000   \n",
      "1%          0.000000      0.000000       0.000000        0.000000   \n",
      "5%          0.000000      1.000000       0.000000        0.000000   \n",
      "50%         0.000000     11.000000       0.000000        0.000000   \n",
      "95%         0.000000     31.000000       5.000000        0.012270   \n",
      "99%         0.000000     42.000000      14.000000        0.025424   \n",
      "max         1.000000     64.000000     175.000000        0.147541   \n",
      "\n",
      "               label  \n",
      "count  370803.000000  \n",
      "mean        0.003517  \n",
      "std         0.059197  \n",
      "min         0.000000  \n",
      "1%          0.000000  \n",
      "5%          0.000000  \n",
      "50%         0.000000  \n",
      "95%         0.000000  \n",
      "99%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "Где дырки в данных:\n",
      "                Количество    Процент\n",
      "age_diff            314176  84.728549\n",
      "jaccard_groups           1   0.000270\n",
      "\n",
      "Как распределён таргет:\n",
      "label\n",
      "0    369499\n",
      "1      1304\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    0.996483\n",
      "1    0.003517\n",
      "Name: count, dtype: float64\n",
      "Смотрю на признаки, вдруг что-то выбивается.\n",
      "\n",
      "Корреляции с таргетом:\n",
      "jaccard_friends: 0.494\n",
      "adamic_adar: 0.454\n",
      "common_friends: 0.359\n",
      "jaccard_groups: 0.097\n",
      "common_groups: 0.058\n",
      "same_city: 0.038\n",
      "same_school: 0.028\n",
      "same_university: 0.022\n",
      "same_faculty: 0.008\n",
      "age_diff: -0.037\n",
      "Готовлю выборки для обучения.\n",
      "В игру идут 10 признаков: ['common_friends', 'jaccard_friends', 'adamic_adar', 'same_city', 'same_university', 'same_faculty', 'same_school', 'age_diff', 'common_groups', 'jaccard_groups']\n",
      "Размеры выборок получились такие:\n",
      "train -> (222481, 10)\n",
      "val -> (74161, 10)\n",
      "test -> (74161, 10)\n",
      "Классы в train: {0: 221699, 1: 782}, веса {0: 1.0, 1: 283.50255754475705}\n",
      "Запускаю CatBoost, наберитесь терпения.\n",
      "Весам классов дал: [1.0, 283.50255754475705]\n",
      "0:\ttest: 0.9238922\tbest: 0.9238922 (0)\ttotal: 44.3ms\tremaining: 1m 6s\n",
      "100:\ttest: 0.9302016\tbest: 0.9433164 (34)\ttotal: 4.67s\tremaining: 1m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9433164315\n",
      "bestIteration = 34\n",
      "\n",
      "Shrink model to first 35 iterations.\n",
      "Считаю метрики по train/val/test.\n",
      "\n",
      "ROC-AUC по выборкам:\n",
      "train: 0.9384\n",
      "val: 0.9433\n",
      "test: 0.9342\n",
      "\n",
      "Accuracy по выборкам:\n",
      "train: 0.9718\n",
      "val: 0.9727\n",
      "test: 0.9716\n",
      "Смотрю, какие признаки тянут модель.\n",
      "\n",
      "Топ-15 по важности:\n",
      "           feature  importance\n",
      "0   common_friends   43.611408\n",
      "2      adamic_adar   16.014463\n",
      "1  jaccard_friends   11.681376\n",
      "9   jaccard_groups   10.252913\n",
      "7         age_diff    7.113600\n",
      "3        same_city    5.837074\n",
      "8    common_groups    4.695456\n",
      "6      same_school    0.602329\n",
      "4  same_university    0.173719\n",
      "5     same_faculty    0.017662\n",
      "\n",
      "Готово, вот финальные цифры:\n",
      "ROC-AUC на тесте: 0.9342\n",
      "Accuracy: 0.9716\n",
      "Сохранил модель в catboost_friendship_model.cbm\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    NEGATIVE_SAMPLING_CONFIG = {}\n",
    "\n",
    "    RESAMPLING_CONFIG = {}\n",
    "\n",
    "    neg_config = NEGATIVE_SAMPLING_CONFIG if any(NEGATIVE_SAMPLING_CONFIG.values()) else None\n",
    "    res_config = RESAMPLING_CONFIG if RESAMPLING_CONFIG.get('strategy') else None\n",
    "\n",
    "    model, importance_df, metrics = main(\n",
    "        negative_sampling_config=neg_config,\n",
    "        resampling_config=res_config,\n",
    "        drop_unrealistic_age=True,\n",
    "        random_state=42,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
